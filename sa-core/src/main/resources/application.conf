// spark conf
spark {
  streaming.trigger.time.interval.msec = 1000
  streaming.future.task.timeout.msec = 300000
  show.table.numRows = 100
  show.table.truncate = true

  redis.host = 127.0.0.1
  redis.port = 6379
  redis.db = 4
//  redis.auth =
//  redis.timeout =
//  redis.max.pipeline.size =
//  redis.scan.count =
}


sqlalarm {
  // event sources, can more than one
  sources = "kafka,redis"

  // alarm event input source conf
  input {
    kafka {
      topic = " sqlalarm_event"
      subscribe.topic.pattern = 1
      bootstrap.servers = "127.0.0.1:9092"
      group = "sqlalarm_group"
    }

  }

  // alarm sink, can more than one
  sinks = "console,kafka,mysql"

  // alarm record sink canal conf
  output {
    kafka {

    }
    mysql {
      url = ""
      driver = ""
      user = ""
      password = ""
    }
  }

  checkpointLocation = "checkpoint"

  // alarm alert conf, use rest api usually
  alert {
    pigeonApi = "https://dt.sqlclub/api/pigeon"
  }
}